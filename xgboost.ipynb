{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8c79f1f",
   "metadata": {},
   "source": [
    "Load necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b162447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from statistics import mean\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c7f012",
   "metadata": {},
   "source": [
    "# I. Model Testing on All Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2e1d34",
   "metadata": {},
   "source": [
    "Create explanatory and response variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07514c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "X = df.drop(['outcome'], axis=1)\n",
    "y = pd.get_dummies(df['outcome'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e91e85",
   "metadata": {},
   "source": [
    "Identify numeric and categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3c05d68-81a4-45bc-8972-4ce1a6da7792",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = X.select_dtypes(include=['number']).columns\n",
    "\n",
    "categorical_columns = list(set(X.columns) - set(numeric_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a5a41b",
   "metadata": {},
   "source": [
    "Preprocess data. Need column names for importance so do transformations seperately and join dfs after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2db7e39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r_kd</th>\n",
       "      <th>r_sub.att</th>\n",
       "      <th>r_rev.</th>\n",
       "      <th>r_ctrl_s</th>\n",
       "      <th>r_sig_str_percent</th>\n",
       "      <th>r_sig_str_att</th>\n",
       "      <th>r_total_str_percent</th>\n",
       "      <th>r_total_str_att</th>\n",
       "      <th>r_td_percent</th>\n",
       "      <th>r_td_att</th>\n",
       "      <th>...</th>\n",
       "      <th>weightclass_Light Heavyweight</th>\n",
       "      <th>weightclass_Lightweight</th>\n",
       "      <th>weightclass_Middleweight</th>\n",
       "      <th>weightclass_Welterweight</th>\n",
       "      <th>weightclass_Women's Bantamweight Bout</th>\n",
       "      <th>weightclass_Women's Featherweight</th>\n",
       "      <th>weightclass_Women's Flyweight Bout</th>\n",
       "      <th>weightclass_Women's Strawweight</th>\n",
       "      <th>title_False</th>\n",
       "      <th>title_True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.444444</td>\n",
       "      <td>0.410538</td>\n",
       "      <td>202.444444</td>\n",
       "      <td>0.431990</td>\n",
       "      <td>213.611111</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>195.666667</td>\n",
       "      <td>0.426600</td>\n",
       "      <td>132.833333</td>\n",
       "      <td>0.514486</td>\n",
       "      <td>166.833333</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>132.500000</td>\n",
       "      <td>0.502677</td>\n",
       "      <td>106.714286</td>\n",
       "      <td>0.545293</td>\n",
       "      <td>120.642857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>123.111111</td>\n",
       "      <td>0.390576</td>\n",
       "      <td>106.111111</td>\n",
       "      <td>0.497585</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       r_kd  r_sub.att    r_rev.    r_ctrl_s  r_sig_str_percent  \\\n",
       "0  0.222222   0.222222  0.000000  100.444444           0.410538   \n",
       "1  0.166667   0.000000  0.000000  195.666667           0.426600   \n",
       "2  0.571429   0.285714  0.214286  132.500000           0.502677   \n",
       "3  0.333333   0.222222  0.111111  123.111111           0.390576   \n",
       "4  1.000000   0.000000  0.000000   47.000000           0.693878   \n",
       "\n",
       "   r_sig_str_att  r_total_str_percent  r_total_str_att  r_td_percent  \\\n",
       "0     202.444444             0.431990       213.611111      0.642857   \n",
       "1     132.833333             0.514486       166.833333      0.280000   \n",
       "2     106.714286             0.545293       120.642857      0.500000   \n",
       "3     106.111111             0.497585       138.000000      0.428571   \n",
       "4      49.000000             0.716981        53.000000      0.250000   \n",
       "\n",
       "   r_td_att  ...  weightclass_Light Heavyweight  weightclass_Lightweight  \\\n",
       "0  1.555556  ...                            0.0                      0.0   \n",
       "1  4.166667  ...                            0.0                      1.0   \n",
       "2  2.714286  ...                            0.0                      0.0   \n",
       "3  0.777778  ...                            0.0                      0.0   \n",
       "4  4.000000  ...                            0.0                      1.0   \n",
       "\n",
       "   weightclass_Middleweight  weightclass_Welterweight  \\\n",
       "0                       1.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       1.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   weightclass_Women's Bantamweight Bout  weightclass_Women's Featherweight  \\\n",
       "0                                    0.0                                0.0   \n",
       "1                                    0.0                                0.0   \n",
       "2                                    0.0                                0.0   \n",
       "3                                    0.0                                0.0   \n",
       "4                                    0.0                                0.0   \n",
       "\n",
       "   weightclass_Women's Flyweight Bout  weightclass_Women's Strawweight  \\\n",
       "0                                 0.0                              0.0   \n",
       "1                                 0.0                              0.0   \n",
       "2                                 0.0                              0.0   \n",
       "3                                 1.0                              0.0   \n",
       "4                                 0.0                              0.0   \n",
       "\n",
       "   title_False  title_True  \n",
       "0          1.0         0.0  \n",
       "1          1.0         0.0  \n",
       "2          1.0         0.0  \n",
       "3          1.0         0.0  \n",
       "4          1.0         0.0  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_pipe = Pipeline([('imputer', SimpleImputer(strategy='median'))])\n",
    "categorical_pipe = Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='missing')), ('ohe', OneHotEncoder(sparse=False))])\n",
    "\n",
    "num_X = pd.DataFrame(numeric_pipe.fit_transform(X[numeric_columns]), columns=numeric_columns)\n",
    "\n",
    "cat_X = categorical_pipe.fit_transform(X[categorical_columns])\n",
    "onehot_col_names = categorical_pipe.named_steps['ohe'].get_feature_names_out(input_features=categorical_columns)\n",
    "cat_X = pd.DataFrame(cat_X, columns=onehot_col_names)\n",
    "\n",
    "X = pd.merge(num_X, cat_X, left_index=True, right_index=True)\n",
    "\n",
    "y = np.ravel(y).reshape((-1,))\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc00174e",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3705f41",
   "metadata": {},
   "source": [
    "## Randomized Search\n",
    "Tune model parameters and obtain cv accuracy estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f9181d6-882b-4113-b087-0d7a32983de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest negative log_loss:  -0.5610222536652344\n",
      "Best parameters:  {'n_estimators': 50, 'min_child_weight': 6, 'max_depth': 3, 'learning_rate': 0.15}\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(random_state=1)\n",
    "\n",
    "clf = XGBClassifier(random_state=1, n_jobs=-1)\n",
    "distributions1 = dict(learning_rate = [0.05, 0.1, 0.15],\n",
    "                      n_estimators = [50, 100, 150],\n",
    "                      max_depth = range(2,10),\n",
    "                      min_child_weight = range(1,10))\n",
    "random1 = RandomizedSearchCV(estimator=clf, param_distributions=distributions1,\n",
    "                            scoring='neg_log_loss', n_iter=10, cv=rkf, random_state=1) # TODO Does changing the seed here only change the parameter grid? If so can I change it to obtain better results? Yes\n",
    "random1.fit(X, y)\n",
    "print(\"Highest neg_log_loss: \", random1.best_score_)\n",
    "print(\"Best parameters: \", random1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "061005c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>Negative Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.561022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.561252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.561417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.561452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.561550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.562938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.566242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.574673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.578315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.595246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  min_child_weight  max_depth  learning_rate  Negative Log Loss\n",
       "4            50                 6          3           0.15          -0.561022\n",
       "2            50                 3          3           0.15          -0.561252\n",
       "0           150                 3          2           0.15          -0.561417\n",
       "8           150                 3          6           0.05          -0.561452\n",
       "1           150                 9          2           0.10          -0.561550\n",
       "6           100                 9          9           0.05          -0.562938\n",
       "5           150                 2          3           0.15          -0.566242\n",
       "3           150                 8          6           0.10          -0.574673\n",
       "9            50                 5          9           0.15          -0.578315\n",
       "7           150                 1          8           0.10          -0.595246"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_table1 = pd.concat([pd.DataFrame(random1.cv_results_[\"params\"]),\n",
    "                          pd.DataFrame(random1.cv_results_[\"mean_test_score\"],\n",
    "                                       columns=[\"Negative Log Loss\"])],axis=1)\n",
    "random_table1.sort_values(\"Negative Log Loss\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78f2454",
   "metadata": {},
   "source": [
    "Recalibrate n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f71b97fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "0     0.667364\n",
      "1     0.647476\n",
      "2     0.632641\n",
      "3     0.621181\n",
      "4     0.611558\n",
      "        ...   \n",
      "58    0.560287\n",
      "59    0.560191\n",
      "60    0.560021\n",
      "61    0.560022\n",
      "62    0.559889\n",
      "Name: test-logloss-mean, Length: 63, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "xgb_param = XGBClassifier(learning_rate=0.15, max_depth=3, min_child_weight=6, random_state=1, n_jobs=-1).get_xgb_params()\n",
    "xg = xgb.DMatrix(X.values, label=y)\n",
    "cvresult = xgb.cv(xgb_param, xg, num_boost_round=1000, nfold=5,\n",
    "                  metrics='logloss', early_stopping_rounds=100, seed=1)\n",
    "print(cvresult.shape[0])\n",
    "print(cvresult['test-logloss-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98ea31e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest neg_log_loss:  -0.5611736740420186\n",
      "Best parameters:  {'subsample': 0.8999999999999999, 'reg_lambda': 1, 'reg_alpha': 0.01, 'gamma': 0.8, 'colsample_bytree': 0.6}\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(random_state=1)\n",
    "\n",
    "clf = XGBClassifier(learning_rate=0.15, n_estimators=63, max_depth=3, min_child_weight=6, random_state=1, n_jobs=-1)\n",
    "distributions2 = dict(gamma=np.arange(0,1.1,0.2),\n",
    "                      subsample = np.arange(0.5, 1.0, 0.1),\n",
    "                      colsample_bytree = np.arange(0.4, 1.0, 0.1),\n",
    "                      reg_alpha=[1e-5, 1e-2, 0.1, 1, 100],\n",
    "                      reg_lambda=[1e-5, 1e-2, 0.1, 1, 100])\n",
    "random2 = RandomizedSearchCV(estimator=clf, param_distributions=distributions2,\n",
    "                            scoring='neg_log_loss', n_iter=10, cv=rkf, random_state=33)\n",
    "random2.fit(X, y)\n",
    "print(\"Highest neg_log_loss: \", random2.best_score_)\n",
    "print(\"Best parameters: \", random2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce55914d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsample</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>gamma</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>Negative Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.561174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.561336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.561991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.563341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.564201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.565334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.590562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.594931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.598880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.600046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subsample  reg_lambda  reg_alpha  gamma  colsample_bytree  \\\n",
       "9        0.9     1.00000    0.01000    0.8               0.6   \n",
       "0        0.9     0.10000    0.10000    0.2               0.7   \n",
       "1        0.8     0.00001    1.00000    0.8               0.4   \n",
       "4        0.7     0.01000    0.10000    0.0               0.4   \n",
       "2        0.6     0.01000    1.00000    0.6               0.7   \n",
       "3        0.8   100.00000    0.00001    0.4               0.8   \n",
       "7        0.9     0.01000  100.00000    0.8               0.6   \n",
       "5        0.8     1.00000  100.00000    1.0               0.6   \n",
       "6        0.7     0.00001  100.00000    0.0               0.4   \n",
       "8        0.7   100.00000  100.00000    0.2               0.6   \n",
       "\n",
       "   Negative Log Loss  \n",
       "9          -0.561174  \n",
       "0          -0.561336  \n",
       "1          -0.561991  \n",
       "4          -0.563341  \n",
       "2          -0.564201  \n",
       "3          -0.565334  \n",
       "7          -0.590562  \n",
       "5          -0.594931  \n",
       "6          -0.598880  \n",
       "8          -0.600046  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_table2 = pd.concat([pd.DataFrame(random2.cv_results_[\"params\"]),\n",
    "                          pd.DataFrame(random2.cv_results_[\"mean_test_score\"],\n",
    "                                       columns=[\"Negative Log Loss\"])],axis=1)\n",
    "random_table2.sort_values(\"Negative Log Loss\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d04ef2e",
   "metadata": {},
   "source": [
    "## Regular Grid Search\n",
    "Tune model parameters and obtain cv accuracy estimates.\n",
    "\n",
    "For learning rates, determine the optimum n_estimators, and corresponding accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6df167bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "0      0.683219\n",
      "1      0.674360\n",
      "2      0.666257\n",
      "3      0.658706\n",
      "4      0.652150\n",
      "         ...   \n",
      "99     0.558593\n",
      "100    0.558510\n",
      "101    0.558630\n",
      "102    0.558515\n",
      "103    0.558508\n",
      "Name: test-logloss-mean, Length: 104, dtype: float64\n",
      "46\n",
      "0     0.673892\n",
      "1     0.658654\n",
      "2     0.645228\n",
      "3     0.634244\n",
      "4     0.625008\n",
      "5     0.616943\n",
      "6     0.610301\n",
      "7     0.604548\n",
      "8     0.599439\n",
      "9     0.595171\n",
      "10    0.590926\n",
      "11    0.587384\n",
      "12    0.583950\n",
      "13    0.581350\n",
      "14    0.578960\n",
      "15    0.576352\n",
      "16    0.574626\n",
      "17    0.573122\n",
      "18    0.571528\n",
      "19    0.570151\n",
      "20    0.568799\n",
      "21    0.567751\n",
      "22    0.566846\n",
      "23    0.565865\n",
      "24    0.565271\n",
      "25    0.564632\n",
      "26    0.564196\n",
      "27    0.563558\n",
      "28    0.563040\n",
      "29    0.562812\n",
      "30    0.562569\n",
      "31    0.562203\n",
      "32    0.561912\n",
      "33    0.561738\n",
      "34    0.561296\n",
      "35    0.561236\n",
      "36    0.560788\n",
      "37    0.560707\n",
      "38    0.560296\n",
      "39    0.560188\n",
      "40    0.560165\n",
      "41    0.560014\n",
      "42    0.560121\n",
      "43    0.559779\n",
      "44    0.559404\n",
      "45    0.559265\n",
      "Name: test-logloss-mean, dtype: float64\n",
      "33\n",
      "0     0.665165\n",
      "1     0.644659\n",
      "2     0.628664\n",
      "3     0.616362\n",
      "4     0.606906\n",
      "5     0.599723\n",
      "6     0.593492\n",
      "7     0.588355\n",
      "8     0.583906\n",
      "9     0.579892\n",
      "10    0.576475\n",
      "11    0.574231\n",
      "12    0.571839\n",
      "13    0.570349\n",
      "14    0.568656\n",
      "15    0.566777\n",
      "16    0.566028\n",
      "17    0.564674\n",
      "18    0.564144\n",
      "19    0.563444\n",
      "20    0.562670\n",
      "21    0.562447\n",
      "22    0.562210\n",
      "23    0.561418\n",
      "24    0.561314\n",
      "25    0.561608\n",
      "26    0.561447\n",
      "27    0.561064\n",
      "28    0.561540\n",
      "29    0.561688\n",
      "30    0.561145\n",
      "31    0.560964\n",
      "32    0.560946\n",
      "Name: test-logloss-mean, dtype: float64\n",
      "21\n",
      "0     0.657030\n",
      "1     0.633406\n",
      "2     0.615516\n",
      "3     0.604149\n",
      "4     0.595213\n",
      "5     0.588392\n",
      "6     0.583487\n",
      "7     0.579407\n",
      "8     0.576132\n",
      "9     0.572942\n",
      "10    0.570884\n",
      "11    0.569267\n",
      "12    0.568325\n",
      "13    0.567360\n",
      "14    0.567686\n",
      "15    0.567049\n",
      "16    0.566278\n",
      "17    0.566216\n",
      "18    0.565364\n",
      "19    0.565236\n",
      "20    0.564617\n",
      "Name: test-logloss-mean, dtype: float64\n",
      "16\n",
      "0     0.649482\n",
      "1     0.622069\n",
      "2     0.605374\n",
      "3     0.594187\n",
      "4     0.586364\n",
      "5     0.581144\n",
      "6     0.576340\n",
      "7     0.573009\n",
      "8     0.570596\n",
      "9     0.568853\n",
      "10    0.568277\n",
      "11    0.567951\n",
      "12    0.567227\n",
      "13    0.567708\n",
      "14    0.566920\n",
      "15    0.566738\n",
      "Name: test-logloss-mean, dtype: float64\n",
      "14\n",
      "0     0.642513\n",
      "1     0.614762\n",
      "2     0.598130\n",
      "3     0.587651\n",
      "4     0.581262\n",
      "5     0.576600\n",
      "6     0.574379\n",
      "7     0.572447\n",
      "8     0.570367\n",
      "9     0.569220\n",
      "10    0.569020\n",
      "11    0.569209\n",
      "12    0.568775\n",
      "13    0.568663\n",
      "Name: test-logloss-mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.05, 0.35, 0.05):\n",
    "    xgb_param = XGBClassifier(learning_rate=i, random_state=1).get_xgb_params()\n",
    "    xg = xgb.DMatrix(X.values, label=y)\n",
    "    cvresult = xgb.cv(xgb_param, xg, num_boost_round=1000, nfold=5,\n",
    "                      metrics='logloss', early_stopping_rounds=100, seed=1)\n",
    "    print(cvresult.shape[0])\n",
    "    print(cvresult['test-logloss-mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453696b8",
   "metadata": {},
   "source": [
    "Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7ebc102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest neg_log_loss:  -0.5591411604289879\n",
      "Best parameters: {'max_depth': 6, 'min_child_weight': 5}\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(random_state=1)\n",
    "\n",
    "clf = XGBClassifier(learning_rate=0.05, n_estimators=104, random_state=1, n_jobs=-1)\n",
    "param_grid1 = dict(max_depth=range(2,10,2),\n",
    "                   min_child_weight=range(1,10,2))\n",
    "grid1 = GridSearchCV(estimator=clf, param_grid=param_grid1, scoring='neg_log_loss', cv=rkf, n_jobs=-1)\n",
    "grid1.fit(X, y)\n",
    "print(\"Highest neg_log_loss: \", grid1.best_score_)\n",
    "print(\"Best parameters:\", grid1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e04771c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>Negative Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.559141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.559450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.559827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.559940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.559972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.560170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.560231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.560249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.560555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.560733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.561724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.562047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.562157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.563569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.564880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.565771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.565803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.565829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.565857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.566050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_child_weight  Negative Log Loss\n",
       "12          6                 5          -0.559141\n",
       "7           4                 5          -0.559450\n",
       "6           4                 3          -0.559827\n",
       "11          6                 3          -0.559940\n",
       "8           4                 7          -0.559972\n",
       "5           4                 1          -0.560170\n",
       "13          6                 7          -0.560231\n",
       "14          6                 9          -0.560249\n",
       "9           4                 9          -0.560555\n",
       "10          6                 1          -0.560733\n",
       "19          8                 9          -0.561724\n",
       "18          8                 7          -0.562047\n",
       "17          8                 5          -0.562157\n",
       "16          8                 3          -0.563569\n",
       "15          8                 1          -0.564880\n",
       "0           2                 1          -0.565771\n",
       "3           2                 7          -0.565803\n",
       "2           2                 5          -0.565829\n",
       "1           2                 3          -0.565857\n",
       "4           2                 9          -0.566050"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid1_table = pd.concat([pd.DataFrame(grid1.cv_results_['params']),\n",
    "                         pd.DataFrame(grid1.cv_results_['mean_test_score'],\n",
    "                                      columns=['Negative Log Loss'])],axis=1)\n",
    "\n",
    "grid1_table.sort_values('Negative Log Loss', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5771f13",
   "metadata": {},
   "source": [
    "More fine tuning around optimal params from previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c368c06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest neg_log_loss:  -0.5590370359948695\n",
      "Best parameters: {'max_depth': 5, 'min_child_weight': 5}\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(random_state=1)\n",
    "\n",
    "clf = XGBClassifier(learning_rate=0.05, n_estimators=104, random_state=1, n_jobs=-1)\n",
    "param_grid2 = dict(max_depth=[5,6,7],\n",
    "                   min_child_weight=[4,5,6])\n",
    "grid2 = GridSearchCV(estimator=clf, param_grid=param_grid2, scoring='neg_log_loss', cv=rkf, n_jobs=-1)\n",
    "grid2.fit(X, y)\n",
    "print(\"Highest neg_log_loss: \", grid2.best_score_)\n",
    "print(\"Best parameters:\", grid2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b0886c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>Negative Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.559037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.559073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.559141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.559241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.559439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.559517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.560571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.560805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.560990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  min_child_weight  Negative Log Loss\n",
       "1          5                 5          -0.559037\n",
       "2          5                 6          -0.559073\n",
       "4          6                 5          -0.559141\n",
       "0          5                 4          -0.559241\n",
       "5          6                 6          -0.559439\n",
       "3          6                 4          -0.559517\n",
       "8          7                 6          -0.560571\n",
       "7          7                 5          -0.560805\n",
       "6          7                 4          -0.560990"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2_table = pd.concat([pd.DataFrame(grid2.cv_results_['params']),\n",
    "                         pd.DataFrame(grid2.cv_results_['mean_test_score'],\n",
    "                                      columns=['Negative Log Loss'])],axis=1)\n",
    "\n",
    "grid2_table.sort_values('Negative Log Loss', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9678f12",
   "metadata": {},
   "source": [
    "Recalibrate n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34dab163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n",
      "0      0.683435\n",
      "1      0.674721\n",
      "2      0.666776\n",
      "3      0.659504\n",
      "4      0.652919\n",
      "         ...   \n",
      "133    0.557573\n",
      "134    0.557578\n",
      "135    0.557572\n",
      "136    0.557599\n",
      "137    0.557544\n",
      "Name: test-logloss-mean, Length: 138, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "xgb_param = XGBClassifier(learning_rate=0.05, max_depth=5, min_child_weight=5, random_state=1).get_xgb_params()\n",
    "xg = xgb.DMatrix(X.values, label=y)\n",
    "cvresult = xgb.cv(xgb_param, xg, num_boost_round=1000, nfold=5,\n",
    "                  metrics='logloss', early_stopping_rounds=100, seed=1)\n",
    "print(cvresult.shape[0])\n",
    "print(cvresult['test-logloss-mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa11f4d",
   "metadata": {},
   "source": [
    "Tune gamma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4505439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest neg_log_loss:  -0.5588244634449913\n",
      "Best parameters: {'gamma': 0.6000000000000001}\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(random_state=1)\n",
    "\n",
    "clf = XGBClassifier(learning_rate=0.05, n_estimators=138, max_depth=5, min_child_weight=5, random_state=1, n_jobs=-1)\n",
    "param_grid3 = dict(gamma=np.arange(0,1.2,0.2))\n",
    "grid3 = GridSearchCV(estimator=clf, param_grid=param_grid3, scoring='neg_log_loss', cv=rkf, n_jobs=-1)\n",
    "grid3.fit(X, y)\n",
    "print(\"Highest neg_log_loss: \", grid3.best_score_)\n",
    "print(\"Best parameters:\", grid3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0f5e8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>Negative Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.558824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.558845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.558960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.558963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.559053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.559083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gamma  Negative Log Loss\n",
       "3    0.6          -0.558824\n",
       "4    0.8          -0.558845\n",
       "0    0.0          -0.558960\n",
       "2    0.4          -0.558963\n",
       "5    1.0          -0.559053\n",
       "1    0.2          -0.559083"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid3_table = pd.concat([pd.DataFrame(grid3.cv_results_['params']),\n",
    "                         pd.DataFrame(grid3.cv_results_['mean_test_score'],\n",
    "                                      columns=['Negative Log Loss'])],axis=1)\n",
    "\n",
    "grid3_table.sort_values('Negative Log Loss', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24d5a52",
   "metadata": {},
   "source": [
    "Recalibrate n_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b773d549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n",
      "0      0.683434\n",
      "1      0.674721\n",
      "2      0.666776\n",
      "3      0.659504\n",
      "4      0.652918\n",
      "         ...   \n",
      "108    0.558372\n",
      "109    0.558314\n",
      "110    0.558357\n",
      "111    0.558158\n",
      "112    0.558141\n",
      "Name: test-logloss-mean, Length: 113, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "xgb_param = XGBClassifier(learning_rate=0.05, max_depth=5, min_child_weight=5, gamma=0.6, random_state=1).get_xgb_params()\n",
    "xg = xgb.DMatrix(X.values, label=y)\n",
    "cvresult = xgb.cv(xgb_param, xg, num_boost_round=1000, nfold=5,\n",
    "                  metrics='logloss', early_stopping_rounds=100, seed=1)\n",
    "print(cvresult.shape[0])\n",
    "print(cvresult['test-logloss-mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631bc66",
   "metadata": {},
   "source": [
    "Tune subsample and colsample_bytree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab0c4a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest neg_log_loss:  -0.5585479271728603\n",
      "Best parameters: {'colsample_bytree': 0.9, 'subsample': 1}\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(random_state=1)\n",
    "\n",
    "clf = XGBClassifier(learning_rate=0.05, n_estimators=113,  max_depth=5, min_child_weight=5, gamma=0.6, random_state=1, n_jobs=-1)\n",
    "param_grid4 = dict(subsample=[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "                   colsample_bytree=[0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "grid4 = GridSearchCV(estimator=clf, param_grid=param_grid4, scoring='neg_log_loss', cv=rkf, n_jobs=-1)\n",
    "grid4.fit(X, y)\n",
    "print(\"Highest neg_log_loss: \", grid4.best_score_)\n",
    "print(\"Best parameters:\", grid4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75dd3755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>subsample</th>\n",
       "      <th>Negative Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.558548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.558566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.558607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.558638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.558789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.558848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.558903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.559263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.559378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.559478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.559582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.559591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.559757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.560305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.560365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.560382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.560532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.560618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.560633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.560880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.560922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.560952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.561036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.561123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.561363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.561374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.561424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.561526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.561781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.562021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.562289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.562299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.562368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.562542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.562612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.563805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    colsample_bytree  subsample  Negative Log Loss\n",
       "29               0.9        1.0          -0.558548\n",
       "28               0.9        0.9          -0.558566\n",
       "16               0.7        0.9          -0.558607\n",
       "35               1.0        1.0          -0.558638\n",
       "22               0.8        0.9          -0.558789\n",
       "34               1.0        0.9          -0.558848\n",
       "23               0.8        1.0          -0.558903\n",
       "33               1.0        0.8          -0.559263\n",
       "27               0.9        0.8          -0.559378\n",
       "15               0.7        0.8          -0.559478\n",
       "17               0.7        1.0          -0.559582\n",
       "21               0.8        0.8          -0.559591\n",
       "10               0.6        0.9          -0.559757\n",
       "20               0.8        0.7          -0.560305\n",
       "11               0.6        1.0          -0.560365\n",
       "14               0.7        0.7          -0.560382\n",
       "32               1.0        0.7          -0.560532\n",
       "26               0.9        0.7          -0.560618\n",
       "9                0.6        0.8          -0.560633\n",
       "13               0.7        0.6          -0.560880\n",
       "8                0.6        0.7          -0.560922\n",
       "4                0.5        0.9          -0.560952\n",
       "3                0.5        0.8          -0.561036\n",
       "19               0.8        0.6          -0.561123\n",
       "25               0.9        0.6          -0.561363\n",
       "31               1.0        0.6          -0.561374\n",
       "5                0.5        1.0          -0.561424\n",
       "2                0.5        0.7          -0.561526\n",
       "7                0.6        0.6          -0.561781\n",
       "18               0.8        0.5          -0.562021\n",
       "1                0.5        0.6          -0.562289\n",
       "12               0.7        0.5          -0.562299\n",
       "24               0.9        0.5          -0.562368\n",
       "30               1.0        0.5          -0.562542\n",
       "6                0.6        0.5          -0.562612\n",
       "0                0.5        0.5          -0.563805"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid4_table = pd.concat([pd.DataFrame(grid4.cv_results_['params']),\n",
    "                         pd.DataFrame(grid4.cv_results_['mean_test_score'],\n",
    "                                      columns=['Negative Log Loss'])],axis=1)\n",
    "\n",
    "grid4_table.sort_values('Negative Log Loss', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fc1ae7",
   "metadata": {},
   "source": [
    "Tune regularization parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "487beec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest neg_log_loss:  -0.5585479265570777\n",
      "Best parameters: {'reg_alpha': 1e-05, 'reg_lambda': 1}\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(random_state=1)\n",
    "\n",
    "clf = XGBClassifier(learning_rate=0.05, n_estimators=113, max_depth=5, min_child_weight=5, gamma=0.6,\n",
    "                    colsample_bytree= 0.9, subsample = 1, random_state=1, n_jobs=-1)\n",
    "param_grid5 = dict(reg_alpha=[1e-5, 1e-2, 0.1, 1, 100],\n",
    "                   reg_lambda=[1e-5, 1e-2, 0.1, 1, 100])\n",
    "grid5 = GridSearchCV(estimator=clf, param_grid=param_grid5, scoring='neg_log_loss', cv=rkf, n_jobs=-1)\n",
    "grid5.fit(X, y)\n",
    "print(\"Highest neg_log_loss: \", grid5.best_score_)\n",
    "print(\"Best parameters:\", grid5.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b6a64a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>Negative Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.558548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>-0.558580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.558604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.558661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.558737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>-0.558819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.558821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>-0.558829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.10000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.558867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.559063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>-0.559068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>-0.559075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>-0.559094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>-0.559136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.559138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>-0.559334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.10000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>-0.566141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>-0.566155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>-0.566164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>-0.566240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>-0.588947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.588958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>-0.588962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.589011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>-0.592551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    reg_alpha  reg_lambda  Negative Log Loss\n",
       "3     0.00001     1.00000          -0.558548\n",
       "17    1.00000     0.10000          -0.558580\n",
       "18    1.00000     1.00000          -0.558604\n",
       "8     0.01000     1.00000          -0.558661\n",
       "15    1.00000     0.00001          -0.558737\n",
       "16    1.00000     0.01000          -0.558819\n",
       "5     0.01000     0.00001          -0.558821\n",
       "6     0.01000     0.01000          -0.558829\n",
       "13    0.10000     1.00000          -0.558867\n",
       "10    0.10000     0.00001          -0.559063\n",
       "1     0.00001     0.01000          -0.559068\n",
       "2     0.00001     0.10000          -0.559075\n",
       "12    0.10000     0.10000          -0.559094\n",
       "7     0.01000     0.10000          -0.559136\n",
       "0     0.00001     0.00001          -0.559138\n",
       "11    0.10000     0.01000          -0.559334\n",
       "14    0.10000   100.00000          -0.566141\n",
       "4     0.00001   100.00000          -0.566155\n",
       "9     0.01000   100.00000          -0.566164\n",
       "19    1.00000   100.00000          -0.566240\n",
       "22  100.00000     0.10000          -0.588947\n",
       "20  100.00000     0.00001          -0.588958\n",
       "21  100.00000     0.01000          -0.588962\n",
       "23  100.00000     1.00000          -0.589011\n",
       "24  100.00000   100.00000          -0.592551"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid5_table = pd.concat([pd.DataFrame(grid5.cv_results_['params']),\n",
    "                         pd.DataFrame(grid5.cv_results_['mean_test_score'],\n",
    "                                      columns=['Negative Log Loss'])],axis=1)\n",
    "\n",
    "grid5_table.sort_values('Negative Log Loss', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439937dd",
   "metadata": {},
   "source": [
    "Try lowering the learning rate and adjusting n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43620fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544\n",
      "0      0.691716\n",
      "1      0.690053\n",
      "2      0.688421\n",
      "3      0.686858\n",
      "4      0.685275\n",
      "         ...   \n",
      "539    0.581393\n",
      "540    0.581374\n",
      "541    0.581386\n",
      "542    0.581371\n",
      "543    0.581351\n",
      "Name: test-logloss-mean, Length: 544, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_param = XGBClassifier(learning_rate=0.01, max_depth=5, min_child_weight=5, gamma=0.6,\n",
    "                          colsample_bytree= 0.9, subsample = 1,\n",
    "                          reg_alpha=0.00001, reg_lambda=1, random_state=1, n_jobs=-1).get_xgb_params()\n",
    "xg = xgb.DMatrix(X.values, label=y)\n",
    "cvresult = xgb.cv(xgb_param, xg, num_boost_round=1000, nfold=5,\n",
    "                  metrics='logloss', early_stopping_rounds=100, seed=1)\n",
    "print(cvresult.shape[0])\n",
    "print(cvresult['test-logloss-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb7649ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5837403395475351\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(random_state=1)\n",
    "\n",
    "clf = XGBClassifier(learning_rate=0.01, n_estimators=544, max_depth=5, min_child_weight=5, gamma=0.6,\n",
    "                          colsample_bytree=0.9, subsample=1,\n",
    "                          reg_alpha=0.00001, reg_lambda=1, random_state=1, n_jobs=-1)\n",
    "cv_scores = cross_val_score(estimator=clf, X=X, y=y, scoring='neg_log_loss', cv=rkf, n_jobs=-1)\n",
    "print(mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0642cc9",
   "metadata": {},
   "source": [
    "# Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48fedd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Xgboost Feature Importance')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = XGBClassifier(learning_rate=0.05, n_estimators=114, max_depth=5, min_child_weight=5, gamma=0.6,\n",
    "                          colsample_bytree= 0.9, subsample = 1,\n",
    "                          reg_alpha=0.00001, reg_lambda=1, random_state=1, n_jobs=-1)\n",
    "clf.fit(X, y)\n",
    "sorted_idx = clf.feature_importances_.argsort()[-10:]\n",
    "plt.barh(X.columns[sorted_idx], clf.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac29014",
   "metadata": {},
   "source": [
    "# II. Model Testing on Data With No Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f1cc29",
   "metadata": {},
   "source": [
    "Create explanatory and response variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3880096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_no_na.csv')\n",
    "X = df.drop(['outcome'], axis=1)\n",
    "y = pd.get_dummies(df['outcome'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8ecaba",
   "metadata": {},
   "source": [
    "Identify numeric and categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0eeb0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = X.select_dtypes(include=['number']).columns\n",
    "\n",
    "categorical_columns = list(set(X.columns) - set(numeric_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff62254",
   "metadata": {},
   "source": [
    "Preprocess data. Need column names for importance so do transformations seperately and join dfs after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71ea6fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r_kd</th>\n",
       "      <th>r_sub.att</th>\n",
       "      <th>r_rev.</th>\n",
       "      <th>r_ctrl_s</th>\n",
       "      <th>r_sig_str_percent</th>\n",
       "      <th>r_sig_str_att</th>\n",
       "      <th>r_total_str_percent</th>\n",
       "      <th>r_total_str_att</th>\n",
       "      <th>r_td_percent</th>\n",
       "      <th>r_td_att</th>\n",
       "      <th>...</th>\n",
       "      <th>b_stance_Orthodox</th>\n",
       "      <th>b_stance_Southpaw</th>\n",
       "      <th>b_stance_Switch</th>\n",
       "      <th>title_False</th>\n",
       "      <th>title_True</th>\n",
       "      <th>r_stance_--</th>\n",
       "      <th>r_stance_Open Stance</th>\n",
       "      <th>r_stance_Orthodox</th>\n",
       "      <th>r_stance_Southpaw</th>\n",
       "      <th>r_stance_Switch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.444444</td>\n",
       "      <td>0.410538</td>\n",
       "      <td>202.444444</td>\n",
       "      <td>0.431990</td>\n",
       "      <td>213.611111</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>195.666667</td>\n",
       "      <td>0.426600</td>\n",
       "      <td>132.833333</td>\n",
       "      <td>0.514486</td>\n",
       "      <td>166.833333</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>132.500000</td>\n",
       "      <td>0.502677</td>\n",
       "      <td>106.714286</td>\n",
       "      <td>0.545293</td>\n",
       "      <td>120.642857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>123.111111</td>\n",
       "      <td>0.390576</td>\n",
       "      <td>106.111111</td>\n",
       "      <td>0.497585</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       r_kd  r_sub.att    r_rev.    r_ctrl_s  r_sig_str_percent  \\\n",
       "0  0.222222   0.222222  0.000000  100.444444           0.410538   \n",
       "1  0.166667   0.000000  0.000000  195.666667           0.426600   \n",
       "2  0.571429   0.285714  0.214286  132.500000           0.502677   \n",
       "3  0.333333   0.222222  0.111111  123.111111           0.390576   \n",
       "4  1.000000   0.000000  0.000000   47.000000           0.693878   \n",
       "\n",
       "   r_sig_str_att  r_total_str_percent  r_total_str_att  r_td_percent  \\\n",
       "0     202.444444             0.431990       213.611111      0.642857   \n",
       "1     132.833333             0.514486       166.833333      0.280000   \n",
       "2     106.714286             0.545293       120.642857      0.500000   \n",
       "3     106.111111             0.497585       138.000000      0.428571   \n",
       "4      49.000000             0.716981        53.000000      0.250000   \n",
       "\n",
       "   r_td_att  ...  b_stance_Orthodox  b_stance_Southpaw  b_stance_Switch  \\\n",
       "0  1.555556  ...                1.0                0.0              0.0   \n",
       "1  4.166667  ...                0.0                0.0              1.0   \n",
       "2  2.714286  ...                1.0                0.0              0.0   \n",
       "3  0.777778  ...                1.0                0.0              0.0   \n",
       "4  4.000000  ...                0.0                1.0              0.0   \n",
       "\n",
       "   title_False  title_True  r_stance_--  r_stance_Open Stance  \\\n",
       "0          1.0         0.0          0.0                   0.0   \n",
       "1          1.0         0.0          0.0                   0.0   \n",
       "2          1.0         0.0          0.0                   0.0   \n",
       "3          1.0         0.0          0.0                   0.0   \n",
       "4          1.0         0.0          0.0                   0.0   \n",
       "\n",
       "   r_stance_Orthodox  r_stance_Southpaw  r_stance_Switch  \n",
       "0                1.0                0.0              0.0  \n",
       "1                1.0                0.0              0.0  \n",
       "2                1.0                0.0              0.0  \n",
       "3                1.0                0.0              0.0  \n",
       "4                1.0                0.0              0.0  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_pipe = Pipeline([('imputer', SimpleImputer(strategy='median'))])\n",
    "categorical_pipe = Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='missing')), ('ohe', OneHotEncoder(sparse=False))])\n",
    "\n",
    "num_X = pd.DataFrame(numeric_pipe.fit_transform(X[numeric_columns]), columns=numeric_columns)\n",
    "\n",
    "cat_X = categorical_pipe.fit_transform(X[categorical_columns])\n",
    "onehot_col_names = categorical_pipe.named_steps['ohe'].get_feature_names_out(input_features=categorical_columns)\n",
    "cat_X = pd.DataFrame(cat_X, columns=onehot_col_names)\n",
    "\n",
    "X = pd.merge(num_X, cat_X, left_index=True, right_index=True)\n",
    "\n",
    "y = np.ravel(y).reshape((-1,))\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010944d1",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce92625",
   "metadata": {},
   "source": [
    "## Randomized Search\n",
    "Tune model parameters and obtain cv accuracy estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e76863b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest neg_log_loss:  -0.5831215666655719\n",
      "Best parameters:  {'n_estimators': 150, 'min_child_weight': 9, 'max_depth': 2, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(random_state=1)\n",
    "\n",
    "clf = XGBClassifier(random_state=1, n_jobs=-1)\n",
    "distributions1 = dict(learning_rate = [0.05, 0.1, 0.15],\n",
    "                      n_estimators = [50, 100, 150],\n",
    "                      max_depth = range(2,10),\n",
    "                      min_child_weight = range(1,10))\n",
    "random1 = RandomizedSearchCV(estimator=clf, param_distributions=distributions1,\n",
    "                            scoring='neg_log_loss', n_iter=10, cv=rkf, random_state=1) # TODO Does changing the seed here only change the parameter grid? If so can I change it to obtain better results? Yes\n",
    "random1.fit(X, y)\n",
    "print(\"Highest neg_log_loss: \", random1.best_score_)\n",
    "print(\"Best parameters: \", random1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0a5a678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>Negative Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.583122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.583210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.583595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.585247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.590780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.592079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.594686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.616927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.644530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  min_child_weight  max_depth  learning_rate  Negative Log Loss\n",
       "1           150                 9          2           0.10          -0.583122\n",
       "4            50                 6          3           0.15          -0.583210\n",
       "2            50                 3          3           0.15          -0.583595\n",
       "0           150                 3          2           0.15          -0.585247\n",
       "8           150                 3          6           0.05          -0.590780\n",
       "6           100                 9          9           0.05          -0.592079\n",
       "5           150                 2          3           0.15          -0.594686\n",
       "3           150                 8          6           0.10          -0.610000\n",
       "9            50                 5          9           0.15          -0.616927\n",
       "7           150                 1          8           0.10          -0.644530"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_table1 = pd.concat([pd.DataFrame(random1.cv_results_[\"params\"]),\n",
    "                          pd.DataFrame(random1.cv_results_[\"mean_test_score\"],\n",
    "                                       columns=[\"Negative Log Loss\"])],axis=1)\n",
    "random_table1.sort_values(\"Negative Log Loss\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e441b911",
   "metadata": {},
   "source": [
    "Recalibrate n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a429dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "0      0.678961\n",
      "1      0.667322\n",
      "2      0.657695\n",
      "3      0.649423\n",
      "4      0.642408\n",
      "         ...   \n",
      "103    0.581429\n",
      "104    0.581499\n",
      "105    0.581358\n",
      "106    0.581396\n",
      "107    0.581223\n",
      "Name: test-logloss-mean, Length: 108, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "xgb_param = XGBClassifier(learning_rate=0.1, max_depth=2, min_child_weight=9, random_state=1, n_jobs=-1).get_xgb_params()\n",
    "xg = xgb.DMatrix(X.values, label=y)\n",
    "cvresult = xgb.cv(xgb_param, xg, num_boost_round=1000, nfold=5,\n",
    "                  metrics='logloss', early_stopping_rounds=100, seed=1)\n",
    "print(cvresult.shape[0])\n",
    "print(cvresult['test-logloss-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2d9bce8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest neg_log_loss:  -0.5824535899492106\n",
      "Best parameters:  {'subsample': 0.8999999999999999, 'reg_lambda': 0.1, 'reg_alpha': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.7}\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(random_state=1)\n",
    "\n",
    "clf = XGBClassifier(learning_rate=0.1, n_estimators=108, max_depth=2, min_child_weight=9, random_state=1, n_jobs=-1)\n",
    "distributions2 = dict(gamma=np.arange(0,1.1,0.2),\n",
    "                      subsample = np.arange(0.5, 1.0, 0.1),\n",
    "                      colsample_bytree = np.arange(0.4, 1.0, 0.1),\n",
    "                      reg_alpha=[1e-5, 1e-2, 0.1, 1, 100],\n",
    "                      reg_lambda=[1e-5, 1e-2, 0.1, 1, 100])\n",
    "random2 = RandomizedSearchCV(estimator=clf, param_distributions=distributions2,\n",
    "                            scoring='neg_log_loss', n_iter=10, cv=rkf, random_state=33)\n",
    "random2.fit(X, y)\n",
    "print(\"Highest neg_log_loss: \", random2.best_score_)\n",
    "print(\"Best parameters: \", random2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85a52c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsample</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>gamma</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>Negative Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.582454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.582616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.582904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.583517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.584471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.587599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.622843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.627969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.632881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.634410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subsample  reg_lambda  reg_alpha  gamma  colsample_bytree  \\\n",
       "0        0.9     0.10000    0.10000    0.2               0.7   \n",
       "9        0.9     1.00000    0.01000    0.8               0.6   \n",
       "1        0.8     0.00001    1.00000    0.8               0.4   \n",
       "4        0.7     0.01000    0.10000    0.0               0.4   \n",
       "2        0.6     0.01000    1.00000    0.6               0.7   \n",
       "3        0.8   100.00000    0.00001    0.4               0.8   \n",
       "7        0.9     0.01000  100.00000    0.8               0.6   \n",
       "5        0.8     1.00000  100.00000    1.0               0.6   \n",
       "6        0.7     0.00001  100.00000    0.0               0.4   \n",
       "8        0.7   100.00000  100.00000    0.2               0.6   \n",
       "\n",
       "   Negative Log Loss  \n",
       "0          -0.582454  \n",
       "9          -0.582616  \n",
       "1          -0.582904  \n",
       "4          -0.583517  \n",
       "2          -0.584471  \n",
       "3          -0.587599  \n",
       "7          -0.622843  \n",
       "5          -0.627969  \n",
       "6          -0.632881  \n",
       "8          -0.634410  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_table2 = pd.concat([pd.DataFrame(random2.cv_results_[\"params\"]),\n",
    "                          pd.DataFrame(random2.cv_results_[\"mean_test_score\"],\n",
    "                                       columns=[\"Negative Log Loss\"])],axis=1)\n",
    "random_table2.sort_values(\"Negative Log Loss\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8236ca",
   "metadata": {},
   "source": [
    "## Regular Grid Search\n",
    "Tune model parameters and obtain cv accuracy estimates.\n",
    "\n",
    "For learning rates, determine the optimum n_estimators, and corresponding accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78fc594b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "0     0.684534\n",
      "1     0.676770\n",
      "2     0.669895\n",
      "3     0.663391\n",
      "4     0.657521\n",
      "        ...   \n",
      "79    0.583512\n",
      "80    0.583542\n",
      "81    0.583601\n",
      "82    0.583528\n",
      "83    0.583502\n",
      "Name: test-logloss-mean, Length: 84, dtype: float64\n",
      "31\n",
      "0     0.676493\n",
      "1     0.662769\n",
      "2     0.651973\n",
      "3     0.642601\n",
      "4     0.634399\n",
      "5     0.627823\n",
      "6     0.621971\n",
      "7     0.617073\n",
      "8     0.612771\n",
      "9     0.609694\n",
      "10    0.606367\n",
      "11    0.604046\n",
      "12    0.601513\n",
      "13    0.599488\n",
      "14    0.597298\n",
      "15    0.595677\n",
      "16    0.594502\n",
      "17    0.593262\n",
      "18    0.591874\n",
      "19    0.590761\n",
      "20    0.590040\n",
      "21    0.589314\n",
      "22    0.588637\n",
      "23    0.588124\n",
      "24    0.588079\n",
      "25    0.587761\n",
      "26    0.587790\n",
      "27    0.587418\n",
      "28    0.586802\n",
      "29    0.586624\n",
      "30    0.585953\n",
      "Name: test-logloss-mean, dtype: float64\n",
      "29\n",
      "0     0.669020\n",
      "1     0.651159\n",
      "2     0.637765\n",
      "3     0.627960\n",
      "4     0.620367\n",
      "5     0.614321\n",
      "6     0.609839\n",
      "7     0.605165\n",
      "8     0.601933\n",
      "9     0.599268\n",
      "10    0.597569\n",
      "11    0.595719\n",
      "12    0.594916\n",
      "13    0.593943\n",
      "14    0.592441\n",
      "15    0.592044\n",
      "16    0.591527\n",
      "17    0.591134\n",
      "18    0.590749\n",
      "19    0.590127\n",
      "20    0.589721\n",
      "21    0.589147\n",
      "22    0.589012\n",
      "23    0.589508\n",
      "24    0.589698\n",
      "25    0.589837\n",
      "26    0.589435\n",
      "27    0.589378\n",
      "28    0.588938\n",
      "Name: test-logloss-mean, dtype: float64\n",
      "16\n",
      "0     0.662110\n",
      "1     0.642422\n",
      "2     0.627746\n",
      "3     0.618385\n",
      "4     0.610980\n",
      "5     0.605142\n",
      "6     0.600500\n",
      "7     0.597379\n",
      "8     0.595390\n",
      "9     0.593628\n",
      "10    0.592239\n",
      "11    0.591010\n",
      "12    0.590179\n",
      "13    0.590242\n",
      "14    0.590063\n",
      "15    0.589913\n",
      "Name: test-logloss-mean, dtype: float64\n",
      "13\n",
      "0     0.655758\n",
      "1     0.634070\n",
      "2     0.620936\n",
      "3     0.611551\n",
      "4     0.606155\n",
      "5     0.601756\n",
      "6     0.598701\n",
      "7     0.596868\n",
      "8     0.595233\n",
      "9     0.594242\n",
      "10    0.593170\n",
      "11    0.593002\n",
      "12    0.592887\n",
      "Name: test-logloss-mean, dtype: float64\n",
      "10\n",
      "0    0.649956\n",
      "1    0.627870\n",
      "2    0.615659\n",
      "3    0.608854\n",
      "4    0.605910\n",
      "5    0.602573\n",
      "6    0.600038\n",
      "7    0.599348\n",
      "8    0.599170\n",
      "9    0.597997\n",
      "Name: test-logloss-mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.05, 0.35, 0.05):\n",
    "    xgb_param = XGBClassifier(learning_rate=i, random_state=1).get_xgb_params()\n",
    "    xg = xgb.DMatrix(X.values, label=y)\n",
    "    cvresult = xgb.cv(xgb_param, xg, num_boost_round=1000, nfold=5,\n",
    "                      metrics='logloss', early_stopping_rounds=100, seed=1)\n",
    "    print(cvresult.shape[0])\n",
    "    print(cvresult['test-logloss-mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92d0676",
   "metadata": {},
   "source": [
    "Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f601104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest neg_log_loss:  -0.5829768493991795\n",
      "Best parameters: {'max_depth': 4, 'min_child_weight': 5}\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(random_state=1)\n",
    "\n",
    "clf = XGBClassifier(learning_rate=0.05, n_estimators=84, random_state=1, n_jobs=-1)\n",
    "param_grid1 = dict(max_depth=range(2,10,2),\n",
    "                   min_child_weight=range(1,10,2))\n",
    "grid1 = GridSearchCV(estimator=clf, param_grid=param_grid1, scoring='neg_log_loss', cv=rkf, n_jobs=-1)\n",
    "grid1.fit(X, y)\n",
    "print(\"Highest neg_log_loss: \", grid1.best_score_)\n",
    "print(\"Best parameters:\", grid1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8fe555f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>Negative Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.582977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.583078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.583133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.583145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.583377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.585131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.585179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.585325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.585403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.586336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.586786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.586808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.586838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.586839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.586845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.588795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.589176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.590030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.592320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.593422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_child_weight  Negative Log Loss\n",
       "7           4                 5          -0.582977\n",
       "5           4                 1          -0.583078\n",
       "9           4                 9          -0.583133\n",
       "6           4                 3          -0.583145\n",
       "8           4                 7          -0.583377\n",
       "12          6                 5          -0.585131\n",
       "14          6                 9          -0.585179\n",
       "11          6                 3          -0.585325\n",
       "13          6                 7          -0.585403\n",
       "10          6                 1          -0.586336\n",
       "4           2                 9          -0.586786\n",
       "3           2                 7          -0.586808\n",
       "2           2                 5          -0.586838\n",
       "1           2                 3          -0.586839\n",
       "0           2                 1          -0.586845\n",
       "19          8                 9          -0.588795\n",
       "18          8                 7          -0.589176\n",
       "17          8                 5          -0.590030\n",
       "16          8                 3          -0.592320\n",
       "15          8                 1          -0.593422"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid1_table = pd.concat([pd.DataFrame(grid1.cv_results_['params']),\n",
    "                         pd.DataFrame(grid1.cv_results_['mean_test_score'],\n",
    "                                      columns=['Negative Log Loss'])],axis=1)\n",
    "\n",
    "grid1_table.sort_values('Negative Log Loss', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2159bad7",
   "metadata": {},
   "source": [
    "More fine tuning around optimal params from previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5f3481e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest neg_log_loss:  -0.5829457490873171\n",
      "Best parameters: {'max_depth': 4, 'min_child_weight': 6}\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(random_state=1)\n",
    "\n",
    "clf = XGBClassifier(learning_rate=0.05, n_estimators=84, random_state=1, n_jobs=-1)\n",
    "param_grid2 = dict(max_depth=[3,4,5],\n",
    "                   min_child_weight=[4,5,6])\n",
    "grid2 = GridSearchCV(estimator=clf, param_grid=param_grid2, scoring='neg_log_loss', cv=rkf, n_jobs=-1)\n",
    "grid2.fit(X, y)\n",
    "print(\"Highest neg_log_loss: \", grid2.best_score_)\n",
    "print(\"Best parameters:\", grid2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9f0ecaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>Negative Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.582946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.582977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.583014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.583412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.583438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.583495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.583909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.584027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.584031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  min_child_weight  Negative Log Loss\n",
       "5          4                 6          -0.582946\n",
       "4          4                 5          -0.582977\n",
       "3          4                 4          -0.583014\n",
       "0          3                 4          -0.583412\n",
       "2          3                 6          -0.583438\n",
       "1          3                 5          -0.583495\n",
       "7          5                 5          -0.583909\n",
       "8          5                 6          -0.584027\n",
       "6          5                 4          -0.584031"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2_table = pd.concat([pd.DataFrame(grid2.cv_results_['params']),\n",
    "                         pd.DataFrame(grid2.cv_results_['mean_test_score'],\n",
    "                                      columns=['Negative Log Loss'])],axis=1)\n",
    "\n",
    "grid2_table.sort_values('Negative Log Loss', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa58b7b",
   "metadata": {},
   "source": [
    "Recalibrate n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05421ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "0     0.684642\n",
      "1     0.677033\n",
      "2     0.669989\n",
      "3     0.663824\n",
      "4     0.657944\n",
      "        ...   \n",
      "79    0.582279\n",
      "80    0.582285\n",
      "81    0.582312\n",
      "82    0.582256\n",
      "83    0.582156\n",
      "Name: test-logloss-mean, Length: 84, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "xgb_param = XGBClassifier(learning_rate=0.05, max_depth=5, min_child_weight=3, random_state=1).get_xgb_params()\n",
    "xg = xgb.DMatrix(X.values, label=y)\n",
    "cvresult = xgb.cv(xgb_param, xg, num_boost_round=1000, nfold=5,\n",
    "                  metrics='logloss', early_stopping_rounds=100, seed=1)\n",
    "print(cvresult.shape[0])\n",
    "print(cvresult['test-logloss-mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d91578d",
   "metadata": {},
   "source": [
    "Tune gamma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fee88337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest neg_log_loss:  -0.5839221716242529\n",
      "Best parameters: {'gamma': 0.2}\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(random_state=1)\n",
    "\n",
    "clf = XGBClassifier(learning_rate=0.05, n_estimators=84, max_depth=5, min_child_weight=3, random_state=1, n_jobs=-1)\n",
    "param_grid3 = dict(gamma=np.arange(0,1,0.2))\n",
    "grid3 = GridSearchCV(estimator=clf, param_grid=param_grid3, scoring='neg_log_loss', cv=rkf, n_jobs=-1)\n",
    "grid3.fit(X, y)\n",
    "print(\"Highest neg_log_loss: \", grid3.best_score_)\n",
    "print(\"Best parameters:\", grid3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6b946df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>Negative Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.583922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.583930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.584064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.584099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.584186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gamma  Negative Log Loss\n",
       "1    0.2          -0.583922\n",
       "0    0.0          -0.583930\n",
       "4    0.8          -0.584064\n",
       "3    0.6          -0.584099\n",
       "2    0.4          -0.584186"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid3_table = pd.concat([pd.DataFrame(grid3.cv_results_['params']),\n",
    "                         pd.DataFrame(grid3.cv_results_['mean_test_score'],\n",
    "                                      columns=['Negative Log Loss'])],axis=1)\n",
    "\n",
    "grid3_table.sort_values('Negative Log Loss', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dda8688",
   "metadata": {},
   "source": [
    "Recalibrate n_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98146df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "0     0.315358\n",
      "1     0.322967\n",
      "2     0.330011\n",
      "3     0.336176\n",
      "4     0.342056\n",
      "        ...   \n",
      "72    0.417394\n",
      "73    0.417541\n",
      "74    0.417694\n",
      "75    0.417724\n",
      "76    0.417785\n",
      "Name: test-logloss-mean, Length: 77, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "xgb_param = XGBClassifier(learning_rate=0.05, max_depth=5, min_child_weight=3, gamma=0.2, random_state=1).get_xgb_params()\n",
    "xg = xgb.DMatrix(X.values, label=y)\n",
    "cvresult = xgb.cv(xgb_param, xg, num_boost_round=1000, nfold=5,\n",
    "                  metrics='logloss', early_stopping_rounds=100, seed=1)\n",
    "print(cvresult.shape[0])\n",
    "print(1-cvresult['test-logloss-mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874776e9",
   "metadata": {},
   "source": [
    "Tune subsample and colsample_bytree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94095d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest neg_log_loss:  -0.583501041527509\n",
      "Best parameters: {'colsample_bytree': 1, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(random_state=1)\n",
    "\n",
    "clf = XGBClassifier(learning_rate=0.05, n_estimators=77,  max_depth=5, min_child_weight=3, gamma=0.2, random_state=1, n_jobs=-1)\n",
    "param_grid4 = dict(subsample=[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "                   colsample_bytree=[0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "grid4 = GridSearchCV(estimator=clf, param_grid=param_grid4, scoring='neg_log_loss', cv=rkf, n_jobs=-1)\n",
    "grid4.fit(X, y)\n",
    "print(\"Highest neg_log_loss: \", grid4.best_score_)\n",
    "print(\"Best parameters:\", grid4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f8a8c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>subsample</th>\n",
       "      <th>Negative Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.583501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.583600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.583652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.583660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.584075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.584183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.584402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.584552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.584643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.584660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.584663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.584877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.584926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.584979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.585212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.585309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.585662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.585821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.586013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.586072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.586094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.586366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.586391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.586634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.586697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.586939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.587218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.587581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.587623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.587967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.588060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.588163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.588445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.589111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.590341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.590502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    colsample_bytree  subsample  Negative Log Loss\n",
       "34               1.0        0.9          -0.583501\n",
       "28               0.9        0.9          -0.583600\n",
       "27               0.9        0.8          -0.583652\n",
       "33               1.0        0.8          -0.583660\n",
       "32               1.0        0.7          -0.584075\n",
       "35               1.0        1.0          -0.584183\n",
       "22               0.8        0.9          -0.584402\n",
       "26               0.9        0.7          -0.584552\n",
       "29               0.9        1.0          -0.584643\n",
       "23               0.8        1.0          -0.584660\n",
       "31               1.0        0.6          -0.584663\n",
       "21               0.8        0.8          -0.584877\n",
       "20               0.8        0.7          -0.584926\n",
       "25               0.9        0.6          -0.584979\n",
       "15               0.7        0.8          -0.585212\n",
       "16               0.7        0.9          -0.585309\n",
       "19               0.8        0.6          -0.585662\n",
       "30               1.0        0.5          -0.585821\n",
       "17               0.7        1.0          -0.586013\n",
       "24               0.9        0.5          -0.586072\n",
       "14               0.7        0.7          -0.586094\n",
       "18               0.8        0.5          -0.586366\n",
       "13               0.7        0.6          -0.586391\n",
       "10               0.6        0.9          -0.586634\n",
       "9                0.6        0.8          -0.586697\n",
       "12               0.7        0.5          -0.586939\n",
       "8                0.6        0.7          -0.587218\n",
       "7                0.6        0.6          -0.587581\n",
       "4                0.5        0.9          -0.587623\n",
       "6                0.6        0.5          -0.587967\n",
       "3                0.5        0.8          -0.588060\n",
       "11               0.6        1.0          -0.588163\n",
       "2                0.5        0.7          -0.588445\n",
       "1                0.5        0.6          -0.589111\n",
       "0                0.5        0.5          -0.590341\n",
       "5                0.5        1.0          -0.590502"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid4_table = pd.concat([pd.DataFrame(grid4.cv_results_['params']),\n",
    "                         pd.DataFrame(grid4.cv_results_['mean_test_score'],\n",
    "                                      columns=['Negative Log Loss'])],axis=1)\n",
    "\n",
    "grid4_table.sort_values('Negative Log Loss', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ce42e3",
   "metadata": {},
   "source": [
    "Tune regularization parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79d1e47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest neg_log_loss:  -0.5832891491066186\n",
      "Best parameters: {'reg_alpha': 1e-05, 'reg_lambda': 0.1}\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(random_state=1)\n",
    "\n",
    "clf = XGBClassifier(learning_rate=0.05, n_estimators=77,  max_depth=5, min_child_weight=3, gamma=0.2,\n",
    "                    colsample_bytree=1, subsample=0.9,\n",
    "                    random_state=1, n_jobs=-1)\n",
    "param_grid5 = dict(reg_alpha=[1e-5, 1e-2, 0.1, 1, 100],\n",
    "                   reg_lambda=[1e-5, 1e-2, 0.1, 1, 100])\n",
    "grid5 = GridSearchCV(estimator=clf, param_grid=param_grid5, scoring='neg_log_loss', cv=rkf, n_jobs=-1)\n",
    "grid5.fit(X, y)\n",
    "print(\"Highest neg_log_loss: \", grid5.best_score_)\n",
    "print(\"Best parameters:\", grid5.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a073b057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>Negative Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>-0.583289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>-0.583443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.583493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>-0.583511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.583569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>-0.583600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>-0.583657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>-0.583732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.583756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.583776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>-0.583806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.583917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.10000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.583931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>-0.583944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.583958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.584002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>-0.595689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>-0.595697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.10000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>-0.595722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>-0.595902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>-0.624254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>-0.624257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.624259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.624358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>-0.631622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    reg_alpha  reg_lambda  Negative Log Loss\n",
       "2     0.00001     0.10000          -0.583289\n",
       "1     0.00001     0.01000          -0.583443\n",
       "3     0.00001     1.00000          -0.583493\n",
       "7     0.01000     0.10000          -0.583511\n",
       "5     0.01000     0.00001          -0.583569\n",
       "12    0.10000     0.10000          -0.583600\n",
       "6     0.01000     0.01000          -0.583657\n",
       "11    0.10000     0.01000          -0.583732\n",
       "0     0.00001     0.00001          -0.583756\n",
       "15    1.00000     0.00001          -0.583776\n",
       "16    1.00000     0.01000          -0.583806\n",
       "8     0.01000     1.00000          -0.583917\n",
       "13    0.10000     1.00000          -0.583931\n",
       "17    1.00000     0.10000          -0.583944\n",
       "10    0.10000     0.00001          -0.583958\n",
       "18    1.00000     1.00000          -0.584002\n",
       "4     0.00001   100.00000          -0.595689\n",
       "9     0.01000   100.00000          -0.595697\n",
       "14    0.10000   100.00000          -0.595722\n",
       "19    1.00000   100.00000          -0.595902\n",
       "21  100.00000     0.01000          -0.624254\n",
       "22  100.00000     0.10000          -0.624257\n",
       "20  100.00000     0.00001          -0.624259\n",
       "23  100.00000     1.00000          -0.624358\n",
       "24  100.00000   100.00000          -0.631622"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid5_table = pd.concat([pd.DataFrame(grid5.cv_results_['params']),\n",
    "                         pd.DataFrame(grid5.cv_results_['mean_test_score'],\n",
    "                                      columns=['Negative Log Loss'])],axis=1)\n",
    "\n",
    "grid5_table.sort_values('Negative Log Loss', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbbea6a",
   "metadata": {},
   "source": [
    "Try lowering the learning rate and adjusting n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d44d4b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481\n",
      "0      0.691428\n",
      "1      0.689672\n",
      "2      0.687981\n",
      "3      0.686313\n",
      "4      0.684728\n",
      "         ...   \n",
      "476    0.580230\n",
      "477    0.580229\n",
      "478    0.580243\n",
      "479    0.580256\n",
      "480    0.580228\n",
      "Name: test-logloss-mean, Length: 481, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_param = XGBClassifier(learning_rate=0.01, max_depth=5, min_child_weight=3, gamma=0.2,\n",
    "                          colsample_bytree=1, subsample=0.9, reg_alpha=0.00001, reg_lambda=0.1,\n",
    "                          random_state=1, n_jobs=-1).get_xgb_params()\n",
    "xg = xgb.DMatrix(X.values, label=y)\n",
    "cvresult = xgb.cv(xgb_param, xg, num_boost_round=1000, nfold=5,\n",
    "                  metrics='logloss', early_stopping_rounds=100, seed=1)\n",
    "print(cvresult.shape[0])\n",
    "print(cvresult['test-logloss-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "527400ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.582121891248411\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(random_state=1)\n",
    "\n",
    "clf = XGBClassifier(learning_rate=0.01, n_estimators=481, max_depth=5, min_child_weight=3, gamma=0.2,\n",
    "                    colsample_bytree=1, subsample=0.9, reg_alpha=0.00001, reg_lambda=0.1,\n",
    "                    random_state=1, n_jobs=-1)\n",
    "cv_scores = cross_val_score(estimator=clf, X=X, y=y, scoring='neg_log_loss', cv=rkf, n_jobs=-1)\n",
    "print(mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363551cf",
   "metadata": {},
   "source": [
    "# Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "947a64bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Xgboost Feature Importance')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = XGBClassifier(learning_rate=0.01, n_estimators=481, max_depth=5, min_child_weight=3, gamma=0.2,\n",
    "                    colsample_bytree=1, subsample=0.9, reg_alpha=0.00001, reg_lambda=0.1,\n",
    "                    random_state=1, n_jobs=-1)\n",
    "clf.fit(X, y)\n",
    "sorted_idx = clf.feature_importances_.argsort()[-10:]\n",
    "plt.barh(X.columns[sorted_idx], clf.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a72268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
